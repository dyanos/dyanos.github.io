---
layout: post
title: Fisher Information?
date: 2019-07-29
comments: true
external-url: https://www.facebook.com/fisherinohio/posts/342873913320663
categories: Statistics
---

원본글1 [https://www.facebook.com/fisherinohio/posts/342873913320663]
원본글2 [https://www.facebook.com/fisherinohio/posts/343193673288687]
원본글3 [https://www.facebook.com/fisherinohio/posts/345653829709338]

아래 내용은 원본글의 내용에서 핵심 문장으로 생각되는 것들을 그대로 옮겨온 것 입니다. 더 자세한 사항을 알고 싶으시면, 위 링크를 참조하세요!

> Fisher Information

피셔 정보의 출발점은 확률질량/밀도함수에 로그를 취한 것 (N=1이라고 가정), 다시 말해 로그-가능도함수 log-likelihood 입니다.

1) 피셔 정보량이 (양의 방향으로) 매우 크다 = 로그-가능도함수의 이계도함수 값이 매우 작다 (음의 방향으로 크다) = 로그-가능도가 봉우리 근처에서 매우 급격히 변화한다 = 로그-가능도의 '봉우리'가 매우 뾰족하다 = '봉우리'를 정확하게 찾기가 매우 쉬워진다
2) 피셔 정보량이 작다 (0에 가깝다) = 로그-가능도함수의 이계도함수 값이 대개 0에 가깝다 = 로그-가능도가 봉우리 근처에서 매우 완만히 변화한다 = 로그-가능도의 '봉우리'가 매우 납작하다 = '봉우리'를 정확하게 찾기가 매우 어려워진다
결국 이 모든 이야기를 종합하면 피셔 정보량이 클수록 로그-가능도함수의 봉우리가 뾰족해져서 정확하게 찾을 확률이 높아진다, 다시 말해 모수치에 대해 정확한 '정보'를 얻을 수 있게 된다는 말입니다. 이런 이유로 큰 Fisher Information 은 모수치에 대한 더 많은 정보를 의미한다는 것입니다. 이와 관련된 Fisher Information의 또 한 가지 성질은 샘플 사이즈에 정확히 비례하여 커진다는 것인데, 크기가 N인 표본에서 얻을 수 있는 정보량은 크기가 1인 경우에 계산한 Fisher Information에 정확히 N을 곱한 것과 같습니다. 즉 피셔 정보량은 additive 합니다. 이는 샘플 크기가 클수록 모수치에 대해 더 많은 정보를 얻을 수 있다는 직관과 일치합니다.

모분산의 역수를 precision이라고도 부르는데, 베이지안 통계에서 자주 등장하는 개념입니다. 왜냐하면 사후분포의 precision은 사전분포와 가능도의 precision들의 합과 같다는 유용한 결과가 있기 때문입니다.

간단한 예를 하나 들어보면, 지난 글에서 분산이 알려진 정규분포 모형의 경우 모평균의 피셔 정보량은 분산의 역수, 즉 precision (1/sigma^2) 이라고 했습니다. 그리고 (당연하게도) 모평균에 대한 최대가능도 추정치는 표본평균입니다.

중요한 것은 이렇게 얻은 분산은 일종의 "이론적으로 가능한 최소의 분산"이라는 것입니다. 단 unbiased estimator에 한하여 말입니다. 다시 말해 어떤 unbiased estimator라도 피셔 정보량의 역수보다 작은 분산을 가지는 것이 불가능합니다.  따라서 어떤 unbiased estimator가 피셔 정보량의 역수와 같은 분산을 가진다면, 그것은 이미 "최적"의 unbiased estimator라는 뜻입니다.

